# AURA Complete Setup Guide

## Prerequisites

- Python 3.9+
- NVIDIA GPU (optional but recommended for speed)
- 20GB free disk space (for models + data)
- Ollama + Mistral (for interactive Q&A)

## Step 1: Clone & Create Virtual Environment

\`\`\`bash
git clone https://github.com/yourusername/aura.git
cd aura

# Create environment (Python 3.11)
conda create -n aura_env python=3.11
conda activate aura_env
\`\`\`

## Step 2: Install Dependencies

\`\`\`bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
\`\`\`

If you get build errors (especially on Windows):
\`\`\`bash
# Option A: Pre-built wheels only
pip install --only-binary :all: -r requirements.txt

# Option B: Install individually
pip install pandas numpy matplotlib seaborn scikit-learn pillow tensorflow requests torch
\`\`\`

## Step 3: Setup Pre-trained VisionTextBridge Model

\`\`\`bash
# Create model folder
mkdir -p TextVisionBridge

# Place your trained best_model.h5 here
cp /path/to/best_model.h5 TextVisionBridge/

# Verify
ls TextVisionBridge/best_model.h5  # Should exist
\`\`\`

## Step 4: Install Ollama & Mistral (Optional but Recommended)

For interactive Q&A with Mistral LLM:

\`\`\`bash
# Download from https://ollama.ai/ and install
# OR use package manager:

# macOS
brew install ollama

# Linux
curl https://ollama.ai/install.sh | sh

# Then pull Mistral
ollama pull mistral

# Keep Ollama running (in separate terminal)
ollama serve
\`\`\`

If Ollama not installed, AURA uses fallback text analysis (slower but works).

## Step 5: Test Installation

\`\`\`bash
python examples/quick_start.py
\`\`\`

Expected output:
\`\`\`
‚úì Loaded data: 1000 rows, 10 columns
‚úì Created 15 graphs
‚úì Extracted embeddings (2560-D)
‚úì Generated text descriptions
‚úì Q&A engine ready
üé® Launching GUI...
\`\`\`

## Step 6: Use AURA in Your Project

\`\`\`python
from aura import Aura

# Initialize
aura = Aura()

# Load your CSV data
aura.load_data("your_data.csv")

# Generate insights (15 graphs + embeddings + descriptions)
aura.generate_insights()

# Launch interactive Tkinter GUI
aura.launch_gui()
\`\`\`

The GUI will show:
- üí¨ Chat interface powered by Mistral
- üìä View all 15 generated graphs
- ‚ùì Ask questions about your data
- üîç Get intelligent answers based on visual patterns

## Complete Pipeline Flow

\`\`\`
[1. Load CSV]
        ‚Üì
[2. Validate Data]
        ‚Üì
[3. Generate 15 Graphs]
    ‚Ä¢ Correlation heatmap
    ‚Ä¢ Distribution plots
    ‚Ä¢ Scatter plots
    ‚Ä¢ Box plots (outliers)
    ‚Ä¢ Category analysis
    ‚Ä¢ Data quality
    ‚Ä¢ Feature importance
        ‚Üì
[4. Extract Features (EfficientNetB7)]
    ‚Ä¢ 2560-D embeddings per graph
    ‚Ä¢ Pre-trained on ImageNet
        ‚Üì
[5. Convert to Text (VisionTextBridge)]
    ‚Ä¢ Neural model: embeddings ‚Üí descriptions
    ‚Ä¢ Trained on 100k PlotQA graphs
    ‚Ä¢ Outputs: "shows positive trend", "has outliers", etc.
        ‚Üì
[6. Interactive Q&A (Mistral LLM)]
    ‚Ä¢ Takes text descriptions + your question
    ‚Ä¢ Generates intelligent answers
    ‚Ä¢ Runs locally via Ollama
        ‚Üì
[7. Tkinter GUI Chat Interface]
    ‚Ä¢ Ask questions
    ‚Ä¢ View graphs
    ‚Ä¢ Get instant answers
\`\`\`

## Troubleshooting

### "Module not found: aura"
\`\`\`bash
# Make sure you're in the correct environment
conda activate aura_env
# Install in development mode
pip install -e .
\`\`\`

### "TensorFlow GPU not found"
\`\`\`bash
# Install CUDA support (RTX/GTX only)
pip install tensorflow[and-cuda]==2.13.0

# Test GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
\`\`\`

### "VisionTextBridge model not found"
\`\`\`bash
# Make sure best_model.h5 is in the right place
ls -la TextVisionBridge/best_model.h5

# If not there, copy it:
cp /your/path/to/best_model.h5 TextVisionBridge/
\`\`\`

### "Ollama connection refused"
\`\`\`bash
# Make sure Ollama is running in another terminal
ollama serve

# Test connection
curl http://localhost:11434/api/tags
\`\`\`

### "Out of Memory"
\`\`\`python
# In feature_extractor.py, reduce batch size from 16 to 8
# Or use CPU only (slower but uses less memory)
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
\`\`\`

### Numpy/Pandas build errors on Windows
\`\`\`bash
# Delete old environment
conda env remove -n aura_env

# Recreate with Python 3.10
conda create -n aura_env python=3.10
conda activate aura_env

# Install again
pip install -r requirements.txt
\`\`\`

## Performance Benchmarks

| Component | Speed (GPU) | Speed (CPU) |
|-----------|------------|-----------|
| Load CSV | <1s | <1s |
| Generate 15 graphs | 2-5s | 3-5s |
| Extract embeddings | 10-20s | 120s |
| VisionTextBridge | 5-10s | 20-30s |
| Mistral Q&A | 0.5-1s | 0.5-1s |
| **Total** | **20-40s** | **150-160s** |

## File Structure

\`\`\`
aura/
‚îú‚îÄ‚îÄ __init__.py                      # Package entry point
‚îú‚îÄ‚îÄ core.py                          # Main Aura class
‚îú‚îÄ‚îÄ graph_generator.py               # 15 graph types
‚îú‚îÄ‚îÄ feature_extractor.py             # EfficientNetB7 embeddings
‚îú‚îÄ‚îÄ vision_text_bridge_loader.py     # Load best_model.h5
‚îú‚îÄ‚îÄ qa_engine.py                     # VisionTextBridge + Mistral
‚îú‚îÄ‚îÄ gui.py                           # Tkinter GUI
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ quick_start.py               # Complete example

TextVisionBridge/
‚îî‚îÄ‚îÄ best_model.h5                    # Pre-trained model (you add this)

requirements.txt                     # All dependencies
README.md                           # User guide
SETUP_INSTRUCTIONS.md               # This file
AURA_IEEE_PAPER.md                 # Research paper
\`\`\`

## Next Steps

1. ‚úÖ Complete setup as above
2. üìñ Read `README.md` for usage guide
3. üìö Read `AURA_IEEE_PAPER.md` for methodology
4. üöÄ Run `python examples/quick_start.py`
5. üíæ Push to GitHub
6. üìù Cite in your research

## Support

Issues? Check:
- `README.md` - Common questions
- `AURA_IEEE_PAPER.md` - How it works
- GitHub Issues - Community help

---

**Version**: 1.0.0  
**Last Updated**: November 2025  
**Status**: Ready for Production
